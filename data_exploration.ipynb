{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring different data files to see what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import warnings\n",
    "import concurrent\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "# Third-party Libraries\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "from scipy.stats import mode\n",
    "from scipy.spatial import cKDTree\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "# Rasterio\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "from rasterio.mask import mask\n",
    "\n",
    "# Shapely\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Linear Models\n",
    "from linearmodels.panel import PanelOLS\n",
    "from linearmodels.panel import RandomEffects\n",
    "\n",
    "import os\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set_matplotlib_formats('retina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the rows where urbanization equals 10\n",
    "# data_filtered = data[data.urbanization != 10]\n",
    "\n",
    "# # Check if there are any other urbanization categories that need to be filtered out\n",
    "# # based on the provided list\n",
    "# urban_categories = [30, 23, 22, 21, 13, 12, 11]\n",
    "# data_filtered = data_filtered[data_filtered['urbanization'].isin(urban_categories)]\n",
    "\n",
    "# # Filter out the years 2013 to 2019\n",
    "# data_filtered = data_filtered[(data_filtered['year'] >= 2013) & (data_filtered['year'] <= 2019)]\n",
    "\n",
    "# # Before plotting, let's check the structure again to ensure correctness\n",
    "# data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set the aesthetic style of the plots\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "# # Prepare the boxplot with a trend line\n",
    "# plt.figure(figsize=(14, 8))\n",
    "\n",
    "# # Create a box plot\n",
    "# sns.boxplot(x='urbanization', y='log_consumption', data=data_filtered, palette=\"deep\")\n",
    "\n",
    "# # Calculate the median values for each urbanization category for each year\n",
    "# median_consumption = data_filtered.groupby(['urbanization', 'year'])['log_consumption'].median().reset_index()\n",
    "\n",
    "# # Create a line plot with the median consumption trend\n",
    "# sns.lineplot(x='year', y='log_consumption', data=median_consumption, \n",
    "#              palette='bright', marker='o')\n",
    "\n",
    "# # Enhance the plot\n",
    "# plt.title('Log of Consumption from 2013 to 2019 Across Different Urbanization Categories')\n",
    "# plt.xlabel('Urbanization Category')\n",
    "# plt.ylabel('Log of Residential Median Consumption')\n",
    "# plt.legend(title='Year')\n",
    "\n",
    "# # # Save the plot\n",
    "# # plt_file_path = '/mnt/data/consumption_trends.png'\n",
    "# # plt.savefig(plt_file_path)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(x='urbanization', y='log_consumption', data=data)\n",
    "# plt.title('Non Residential Consumption by Urbanization Level')\n",
    "# plt.xlabel('Urbanization Level')\n",
    "# plt.ylabel('Log of Consumption')\n",
    "# plt.xticks(rotation=45)  # Rotate x labels for better visibility\n",
    "\n",
    "# # Saving the figure with high resolution\n",
    "# plt.savefig('Non Residential_Consumption_by_Urbanization.png', format='png', dpi=300)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_shp_file = \"/gypsum/eguide/projects/ce8760/locations/rwanda_boundary/RWA_adm0.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.read_file(boundary_shp_file).crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to clip tif files and process data into administrative regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admin_boundary(admin_level: str) -> str:\n",
    "    \"\"\"\n",
    "    This function takes in the admin_level string and returns the file path to the shape file\n",
    "\n",
    "    Input:\n",
    "        - admin_level: A string indicating the admin level (district, sector, cell, village, or boundary)\n",
    "\n",
    "    Returns:\n",
    "        - String representing the shape file path\n",
    "    \"\"\"\n",
    "\n",
    "    admin_paths = {\n",
    "        \"district\": \"/gypsum/eguide/projects/ce8760/locations/district/District.shp\",\n",
    "        \"sector\": \"/gypsum/eguide/projects/ce8760/locations/sector/Sector.shp\",\n",
    "        \"cell\": \"/gypsum/eguide/projects/ce8760/locations/cell/Cell.shp\",\n",
    "        \"village\": \"/gypsum/eguide/projects/ce8760/locations/villages/Village.shp\",\n",
    "        \"boundary\": \"/gypsum/eguide/projects/ce8760/locations/rwanda_boundary/RWA_adm0.shp\",\n",
    "    }\n",
    "\n",
    "    admin_ids = {\n",
    "        \"district\": \"Dist_ID\",\n",
    "        \"sector\": \"Sect_ID\",\n",
    "        \"cell\": \"Cell_ID\",\n",
    "        \"village\": \"Village_ID\",\n",
    "        \"boundary\": None,\n",
    "    }\n",
    "\n",
    "    # Use the provided admin_level to directly access the file path from the dictionary\n",
    "    admin_path = admin_paths.get(admin_level.lower())\n",
    "    admin_id = admin_ids.get(admin_level.lower())\n",
    "\n",
    "    if admin_path is None:\n",
    "        raise ValueError(f\"Invalid admin_level: {admin_level}\")\n",
    "\n",
    "    return admin_path, admin_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_tif_chunk(chunk):\n",
    "    tif_file, chunk_bbox = chunk\n",
    "\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        # Create a GeoDataFrame with the chunk bounding box\n",
    "        bbox_gdf = gpd.GeoDataFrame(geometry=[box(*chunk_bbox)], crs=src.crs)\n",
    "\n",
    "        # Open the boundary shapefile\n",
    "        boundary_gdf = gpd.read_file(get_admin_boundary(\"boundary\")[0])\n",
    "        boundary_gdf = boundary_gdf.to_crs(src.crs)\n",
    "\n",
    "        # Intersect the bounding box with the boundary shapefile\n",
    "        intersection = gpd.overlay(boundary_gdf, bbox_gdf, how='intersection')\n",
    "\n",
    "        # Check if the intersection is empty\n",
    "        if intersection.empty:\n",
    "            print(f\"No intersection for chunk: {chunk}\")\n",
    "            return gpd.GeoDataFrame()\n",
    "\n",
    "        # Clip the raster to the intersection geometry\n",
    "        clipped, transform = mask(src, shapes=intersection.geometry, crop=True)\n",
    "\n",
    "        # Create a GeoDataFrame directly from the clipped raster\n",
    "        shapes_gen = rasterio.features.shapes(clipped, transform=transform)\n",
    "        features = [{'geometry': geometry, 'properties': {'pixel_value': value}}\n",
    "                    for (geometry, value) in shapes_gen]\n",
    "        gdf_clipped = gpd.GeoDataFrame.from_features(features, crs=src.crs)\n",
    "\n",
    "        gdf_clipped = gdf_clipped.to_crs((\"EPSG:4326\"))\n",
    "\n",
    "    return gdf_clipped\n",
    "\n",
    "\n",
    "def parallel_clip_large_tif(tif_file, num_chunks=4):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        xmin, ymin, xmax, ymax = src.bounds\n",
    "        chunk_width = (xmax - xmin) / num_chunks\n",
    "\n",
    "        # Define chunks based on bounding box\n",
    "        chunks = [(tif_file, (xmin + i * chunk_width, ymin, xmin + (i + 1) * chunk_width, ymax))\n",
    "                  for i in range(num_chunks)]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(clip_tif_chunk, chunks))\n",
    "\n",
    "    # Merge the results if needed\n",
    "    print(results)\n",
    "    final_result = gpd.GeoDataFrame(pd.concat(results, ignore_index=True), crs='EPSG:4326')\n",
    "\n",
    "    return final_result\n",
    "\n",
    "# # Example usage:\n",
    "# tif_file = '/path/to/large.tif'\n",
    "# clipped_data = parallel_clip_large_tif(tif_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_tif_chunk(chunk):\n",
    "    tif_file, chunk_bbox = chunk\n",
    "\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        # Create a GeoDataFrame with the chunk bounding box\n",
    "        bbox_gdf = gpd.GeoDataFrame(geometry=[box(*chunk_bbox)], crs=src.crs)\n",
    "\n",
    "        # Open the boundary shapefile\n",
    "        boundary_gdf = gpd.read_file(get_admin_boundary(\"boundary\")[0])\n",
    "        boundary_gdf = boundary_gdf.to_crs(src.crs)\n",
    "\n",
    "        # Intersect the bounding box with the boundary shapefile\n",
    "        intersection = gpd.overlay(boundary_gdf, bbox_gdf, how='intersection')\n",
    "\n",
    "        # Check if the intersection is empty\n",
    "        if intersection.empty:\n",
    "            print(f\"No intersection for chunk: {chunk}\")\n",
    "            return gpd.GeoDataFrame()\n",
    "\n",
    "        # Clip the raster to the intersection geometry\n",
    "        clipped, transform = mask(src, shapes=intersection.geometry, crop=True)\n",
    "\n",
    "        # Create a GeoDataFrame directly from the clipped raster\n",
    "        shapes_gen = rasterio.features.shapes(clipped, transform=transform)\n",
    "        features = [{'geometry': geometry, 'properties': {'pixel_value': value}}\n",
    "                    for (geometry, value) in shapes_gen]\n",
    "        gdf_clipped = gpd.GeoDataFrame.from_features(features, crs=src.crs)\n",
    "\n",
    "        gdf_clipped = gdf_clipped.to_crs((\"EPSG:4326\"))\n",
    "\n",
    "    return gdf_clipped\n",
    "\n",
    "def parallel_clip_large_tif(tif_file, num_chunks=4):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        xmin, ymin, xmax, ymax = src.bounds\n",
    "        chunk_width = (xmax - xmin) / num_chunks\n",
    "\n",
    "        # Define chunks based on bounding box\n",
    "        chunks = [(tif_file, (xmin + i * chunk_width, ymin, xmin + (i + 1) * chunk_width, ymax))\n",
    "                  for i in range(num_chunks)]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Filter out chunks with no intersection\n",
    "        valid_chunks = [(tif, bbox) for tif, bbox in chunks if has_intersection(tif, bbox)]\n",
    "        results = list(executor.map(clip_tif_chunk, valid_chunks))\n",
    "\n",
    "    # Merge the results if needed\n",
    "    final_result = gpd.GeoDataFrame(pd.concat(results, ignore_index=True), crs='EPSG:4326')\n",
    "\n",
    "    return final_result\n",
    "\n",
    "def has_intersection(tif_file, bbox):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        bbox_gdf = gpd.GeoDataFrame(geometry=[box(*bbox)], crs=src.crs)\n",
    "        boundary_gdf = gpd.read_file(get_admin_boundary(\"boundary\")[0])\n",
    "        boundary_gdf = boundary_gdf.to_crs(src.crs)\n",
    "        intersection = gpd.overlay(boundary_gdf, bbox_gdf, how='intersection')\n",
    "        return not intersection.empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for computing metrics in administrative boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_administrative_metric(gdf: gpd.GeoDataFrame, admin_level: str, summary_method: str =\"median\") -> gpd.GeoDataFrame:\n",
    "#     \"\"\"\n",
    "#     This function takes in a geopandas dataframe of an index spread across pixels, \n",
    "#     and localizes it to the region under study (i.e. sector, cell, or village).\n",
    "\n",
    "#     Inputs:\n",
    "#         - gdf: Geopandas Geodataframe containing the index being measured\n",
    "#         - admin_level: This is just a string showing if the admin level is \n",
    "#             sector, cell, or village\n",
    "\n",
    "#     Returns:\n",
    "#         - gpd.GeoDataFrame with median calculations for \n",
    "#     \"\"\"\n",
    "\n",
    "#     # Define a helper function for mode calculation\n",
    "#     def calc_mode(x):\n",
    "#         # Calculate mode, returns mode value and count. We only need the value here\n",
    "#         m = mode(x)[0]\n",
    "#         # Handle potential multiple modes by returning the first one\n",
    "#         return m[0]\n",
    "\n",
    "#     # Get the file path and identifier for the specified admin level\n",
    "#     admin_path, admin_id = get_admin_boundary(admin_level=admin_level)\n",
    "\n",
    "#     # Read the admin shapefile\n",
    "#     admin_shp = gpd.read_file(admin_path)\n",
    "\n",
    "#     # Set CRS of admin_shp to EPSG:4326\n",
    "#     admin_shp = admin_shp.to_crs(\"EPSG:4326\")\n",
    "\n",
    "#     # Use GeoPandas sjoin for intersection\n",
    "#     index_summary = gpd.sjoin(admin_shp, gdf, how=\"inner\", op='intersects')\n",
    "\n",
    "#     # Define aggregation method dynamically based on input\n",
    "#     if summary_method == \"mode\":\n",
    "#         agg_method = calc_mode\n",
    "#     else:\n",
    "#         # Use the string method directly for \"median\" or \"mean\"\n",
    "#         agg_method = summary_method\n",
    "\n",
    "#     # Calculate median and retain the first geometry in case of multiple intersections\n",
    "#     index_summary = index_summary.groupby([admin_id]).agg({\n",
    "#         \"pixel_value\": agg_method,\n",
    "#         \"geometry\": \"first\" \n",
    "#     }).reset_index()\n",
    "\n",
    "#     # Create GeoDataFrame with necessary columns and CRS\n",
    "#     index_summary = gpd.GeoDataFrame(index_summary[[admin_id, \"pixel_value\", \"geometry\"]],\n",
    "#                                      geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "#     return index_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_administrative_metric(gdf: gpd.GeoDataFrame, admin_level: str, summary_method: str = \"median\") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    This function takes a GeoPandas DataFrame containing an index spread across pixels, \n",
    "    and aggregates it to a higher administrative level such as sector, cell, or village.\n",
    "\n",
    "    Args:\n",
    "        gdf: GeoPandas GeoDataFrame containing the index values.\n",
    "        admin_level: A string indicating the administrative level ('sector', 'cell', or 'village').\n",
    "\n",
    "    Returns:\n",
    "        GeoDataFrame with aggregated values based on the specified summary method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a helper function for mode calculation\n",
    "    def calc_mode(x):\n",
    "        # Calculate mode using scipy, but ensure it's treated as array-like\n",
    "        modes = mode(x, keepdims=True)  # `keepdims` ensures consistency across versions\n",
    "        if modes.count.size == 0 or modes.mode.size == 0:\n",
    "            return None  # or np.nan or some fallback value\n",
    "        \n",
    "        mode_value = modes.mode[0]\n",
    "        \n",
    "        if mode_value == 10:\n",
    "            # Exclude 10 and try again\n",
    "            new_modes = mode(x[x != mode_value], keepdims=True)\n",
    "            return new_modes.mode[0] if new_modes.count.size > 0 else mode_value\n",
    "        \n",
    "        return mode_value\n",
    "\n",
    "    # Get the file path and identifier for the specified admin level\n",
    "    admin_path, admin_id = get_admin_boundary(admin_level=admin_level)\n",
    "\n",
    "    # Read the admin shapefile\n",
    "    admin_shp = gpd.read_file(admin_path)\n",
    "\n",
    "    # Set CRS of admin_shp to EPSG:4326\n",
    "    admin_shp = admin_shp.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Use GeoPandas sjoin for spatial join by intersection\n",
    "    index_summary = gpd.sjoin(admin_shp, gdf, how=\"inner\", predicate='intersects')\n",
    "\n",
    "    # Define aggregation method dynamically based on input\n",
    "    if summary_method == \"mode\":\n",
    "        agg_method = calc_mode\n",
    "    else:\n",
    "        # Use the string method directly for \"median\" or \"mean\"\n",
    "        agg_method = summary_method\n",
    "\n",
    "    # Aggregate data and retain the first geometry in case of multiple intersections\n",
    "    index_summary = index_summary.groupby([admin_id]).agg({\n",
    "        \"pixel_value\": agg_method,\n",
    "        \"geometry\": \"first\" \n",
    "    }).reset_index()\n",
    "\n",
    "    # Create a new GeoDataFrame with the necessary columns and CRS\n",
    "    index_summary = gpd.GeoDataFrame(index_summary[[admin_id, \"pixel_value\", \"geometry\"]],\n",
    "                                     geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    return index_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geopandas(gdf, column, figsize=(10, 8), cmap=\"Reds\", \n",
    "                             colorbar_title=\"Colorbar Title\", plot_title=\"plot title\",\n",
    "                             boundary_shp_file=\"/gypsum/eguide/projects/ce8760/locations/rwanda_boundary/RWA_adm0.shp\"):\n",
    "    \"\"\"\n",
    "    This function plots a geopandas shapefile to show the disdribution of an attribute\n",
    "\n",
    "    Parameters:\n",
    "        - gdf: GeoPandas GeoDataFrame to be plotted.\n",
    "        - column: Name of the column in the GeoDataFrame to be used for coloring.\n",
    "        - figsize: Tuple specifying the figure size (default is (10, 8)).\n",
    "        - cmap: Colormap to be used for coloring (default is \"viridis\").\n",
    "\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    # Set the style using seaborn\n",
    "    sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "    sns.set(font_scale=0.7, rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "    # sns.set(font=\"Verdana\", font_scale=0.7, rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "\n",
    "    # Load the boundary shapefile and reproject to EPSG:4326\n",
    "    boundary_gdf = gpd.read_file(boundary_shp_file).to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Reproject the main GeoDataFrame to EPSG:4326\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Plot the boundary line (adjust linewidth and color)\n",
    "    boundary_gdf.boundary.plot(ax=ax, linewidth=0.5, color=\"black\")\n",
    "\n",
    "    # Plot the GeoDataFrame with the specified column for coloring\n",
    "    gdf.plot(column=column, cmap=cmap, linewidth=0.2, ax=ax, edgecolor=\"0.5\")\n",
    "\n",
    "    # Remove axis labels and boundary box\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Show the colormap legend on the side with 4 decimal places and without the boundary box\n",
    "    cax = fig.add_axes([0.92, 0.2, 0.05, 0.2])  # Adjust the position as needed\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=gdf[column].min(), vmax=gdf[column].max()))\n",
    "    sm._A = []  # fake up the array of the scalar mappable\n",
    "    cbar = fig.colorbar(sm, cax=cax, format=\"%.1f\", drawedges=False)  # format=\"%.4f\" for 4 decimal places\n",
    "\n",
    "    # Set the title for the colorbar\n",
    "    cbar.set_label(colorbar_title, rotation=270, labelpad=15)\n",
    "\n",
    "    # Add title to the bottom of the plot\n",
    "    # plt.suptitle(plot_title, x=0.5, y=0.05, fontsize=12, fontname=\"Verdana\",\n",
    "    #              ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle(plot_title, x=0.5, y=0.05, fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geopandas_grid(gdf, years, figsize=(12, 12), cmap=\"Reds\", colorbar_title=\"Colorbar Title\", \n",
    "                        boundary_shp_file=\"/gypsum/eguide/projects/ce8760/locations/rwanda_boundary/RWA_adm0.shp\", filename=None):\n",
    "    \"\"\"\n",
    "    This function plots a geopandas GeoDataFrame on a 3x3 grid, showing the distribution of attributes for the specified years.\n",
    "\n",
    "    Parameters:\n",
    "        - gdf: GeoPandas GeoDataFrame with columns ['administrative_boundary', '2012', '2013', ..., '2020', 'geometry'].\n",
    "        - years: List of years to be plotted (e.g., ['2013', '2014', ..., '2019']).\n",
    "        - figsize: Tuple specifying the figure size (default is (15, 15)).\n",
    "        - cmap: Colormap to be used for coloring (default is \"Reds\").\n",
    "        - colorbar_title: Title for the colorbar.\n",
    "        - boundary_shp_file: Path to the shapefile containing the boundary.\n",
    "        - filename: Optional filename to save the plot as an SVG file.\n",
    "\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    # Load the boundary shapefile and reproject to EPSG:4326\n",
    "    boundary_gdf = gpd.read_file(boundary_shp_file).to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Reproject the main GeoDataFrame to EPSG:4326\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Set the style using seaborn\n",
    "    sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "    # sns.set(font=\"Verdana\", font_scale=0.7, rc={\"figure.dpi\": 300, 'savefig.dpi': 300})\n",
    "    sns.set(font_scale=0.7, rc={\"figure.dpi\": 300, 'savefig.dpi': 300})\n",
    "\n",
    "    # Create the subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=figsize, sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot each year on the grid\n",
    "    for i, year in enumerate(years):\n",
    "        row, col = divmod(i, 3)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        # Plot the boundary line (adjust linewidth and color)\n",
    "        boundary_gdf.boundary.plot(ax=ax, linewidth=0.5, color=\"black\")\n",
    "\n",
    "        # Plot the GeoDataFrame with the specified column for coloring\n",
    "        gdf.plot(column=year, cmap=cmap, linewidth=0.2, ax=ax, edgecolor=\"0.5\", legend=False)\n",
    "\n",
    "        # Remove axis labels and boundary box\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        # Add title\n",
    "        ax.set_title(year, fontsize=10)\n",
    "\n",
    "    # Create a common colorbar for the last column\n",
    "    cax = fig.add_axes([0.95, 0.15, 0.02, 0.7])  # Adjust the position and size as needed\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=gdf[years].min().min(), vmax=gdf[years].max().max()))\n",
    "    sm._A = []  # fake up the array of the scalar mappable\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation=\"vertical\", format=\"%d\", drawedges=False)  # Remove decimals\n",
    "    cbar.set_label(colorbar_title, labelpad=15)\n",
    "\n",
    "    # Hide axes for the last row\n",
    "    for ax in axes[-1, :-2]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Remove the empty subplot in the last row\n",
    "    fig.delaxes(axes[-1, -1])\n",
    "    fig.delaxes(axes[-1, -2])\n",
    "\n",
    "    # Save or display the plot\n",
    "    if filename:\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_geopandas_grid(gdf, years, figsize=(10, 10), cmap=\"Reds\", colorbar_title=\"Colorbar Title\", filename=\"output_plot.svg\")\n",
    "# or\n",
    "# plot_geopandas_grid(gdf, years, figsize=(10, 10), cmap=\"Reds\", colorbar_title=\"Colorbar Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_geopandas_grid(gdf, years, figsize=(12, 12), cmap=\"Reds\", colorbar_title=\"Colorbar Title\", \n",
    "                        boundary_shp_file=\"/gypsum/eguide/projects/ce8760/locations/rwanda_boundary/RWA_adm0.shp\", filename=None):\n",
    "    \"\"\"\n",
    "    This function plots a geopandas GeoDataFrame on a 3x3 grid, showing the distribution of attributes for the specified years.\n",
    "\n",
    "    Parameters:\n",
    "        - gdf: GeoPandas GeoDataFrame with columns ['administrative_boundary', '2012', '2013', ..., '2020', 'geometry'].\n",
    "        - years: List of years to be plotted (e.g., ['2013', '2014', ..., '2019']).\n",
    "        - figsize: Tuple specifying the figure size (default is (15, 15)).\n",
    "        - cmap: Colormap to be used for coloring (default is \"Reds\").\n",
    "        - colorbar_title: Title for the colorbar.\n",
    "        - boundary_shp_file: Path to the shapefile containing the boundary.\n",
    "        - filename: Optional filename to save the plot as an SVG file.\n",
    "\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    # Load the boundary shapefile and reproject to EPSG:4326\n",
    "    boundary_gdf = gpd.read_file(boundary_shp_file).to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Reproject the main GeoDataFrame to EPSG:4326\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Set the style using seaborn\n",
    "    sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "    sns.set(font_scale=0.7, rc={\"figure.dpi\": 300, 'savefig.dpi': 300})\n",
    "    # sns.set(font=\"Verdana\", font_scale=0.7, rc={\"figure.dpi\": 300, 'savefig.dpi': 300})\n",
    "\n",
    "    # Create the subplots\n",
    "    fig, axes = plt.subplots(3, 3, figsize=figsize, sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot each year on the grid\n",
    "    for i, year in enumerate(years):\n",
    "        row, col = divmod(i, 3)\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        # Plot the boundary line (adjust linewidth and color)\n",
    "        boundary_gdf.boundary.plot(ax=ax, linewidth=0.5, color=\"black\")\n",
    "\n",
    "        # Plot the GeoDataFrame with the specified column for coloring\n",
    "        gdf.plot(column=year, cmap=cmap, linewidth=0.2, ax=ax, edgecolor=\"0.5\", legend=False)\n",
    "\n",
    "        # Remove axis labels and boundary box\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        # Add title\n",
    "        ax.set_title(year, fontsize=10)\n",
    "\n",
    "    # Create a common colorbar for the last column\n",
    "    cax = fig.add_axes([0.95, 0.15, 0.02, 0.7])  # Adjust the position and size as needed\n",
    "    vmin, vmax = gdf[years].min().min(), gdf[years].max().max()\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm._A = []  # fake up the array of the scalar mappable\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation=\"vertical\", format=\"%d\", drawedges=False)  # Remove decimals\n",
    "    cbar.set_label(colorbar_title, labelpad=15)\n",
    "\n",
    "    # Set colorbar ticks\n",
    "    cbar.set_ticks([vmin, (vmin + vmax) / 2, vmax])\n",
    "\n",
    "    # Hide axes for the last row\n",
    "    for ax in axes[-1, :-2]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Remove the empty subplot in the last row\n",
    "    fig.delaxes(axes[-1, -1])\n",
    "    fig.delaxes(axes[-1, -2])\n",
    "\n",
    "    # Save or display the plot\n",
    "    if filename:\n",
    "        plt.savefig(filename, format=\"png\", bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_geopandas_grid(gdf, years, figsize=(10, 10), cmap=\"Reds\", colorbar_title=\"Colorbar Title\", filename=\"output_plot.svg\")\n",
    "# or\n",
    "# plot_geopandas_grid(gdf, years, figsize=(10, 10), cmap=\"Reds\", colorbar_title=\"Colorbar Title\")\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for calculating distance to amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def calculate_min_distances(combined_data, marketplace_geojson):\n",
    "    # Extract relevant columns from combined_data\n",
    "    meters_data = combined_data[['meter_serial_number', 'geometry', 'transaction_date']].copy()\n",
    "\n",
    "    # Extract relevant columns from marketplace_geojson\n",
    "    marketplaces = marketplace_geojson[['id', 'geometry']].copy()\n",
    "\n",
    "    # Convert polygon geometries to centroids\n",
    "    marketplaces['geometry'] = marketplaces['geometry'].apply(lambda geom: geom.centroid if geom.type == 'Polygon' else geom)\n",
    "\n",
    "    # Create KD-Tree for marketplaces\n",
    "    marketplace_tree = cKDTree(marketplaces['geometry'].apply(lambda geom: (geom.x, geom.y)).tolist())\n",
    "\n",
    "    # Calculate all distances for each meter\n",
    "    meter_coords = meters_data['geometry'].apply(lambda geom: (geom.x, geom.y)).tolist()\n",
    "    _, indices = marketplace_tree.query(meter_coords, k=1)\n",
    "    distances = marketplaces.loc[indices, 'geometry'].apply(lambda geom: geom.distance(Point(coord)) for coord in meter_coords)\n",
    "\n",
    "    # Create a dataframe to store meter_serial_number, geometry, and distance_to_marketplace\n",
    "    distances_df = meters_data[['meter_serial_number', 'geometry']].copy()\n",
    "\n",
    "    # Create columns for each month in the transaction date\n",
    "    months = meters_data['transaction_date'].dt.strftime('%Y-%m').unique()\n",
    "    distances_df = pd.concat([distances_df] + [pd.Series(name=month) for month in months], axis=1)\n",
    "\n",
    "    # Update distances_df with the calculated distances\n",
    "    distances_df[months] = distances.values.reshape((-1, 1))\n",
    "\n",
    "    return distances_df\n",
    "\n",
    "# # Example usage\n",
    "# combined_data = pd.read_pickle('path/to/combined_data.pkl')\n",
    "# marketplace_geojson = gpd.read_file('path/to/marketplace.geojson')\n",
    "# result_df = calculate_min_distances(combined_data, marketplace_geojson)\n",
    "# result_df.to_csv('path/to/output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all datasets needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepaid electricity transactions as consumption data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas AI asset wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset Wealth\n",
    "\n",
    "asset_wealth_2016_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Asset-Wealth-1912m_0_08_RWA_2016.tif\")\n",
    "asset_wealth_2017_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Asset-Wealth-1912m_0_08_RWA_2017.tif\")\n",
    "asset_wealth_2018_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Asset-Wealth-1912m_0_08_RWA_2018.tif\")\n",
    "asset_wealth_2019_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Asset-Wealth-1912m_0_08_RWA_2019.tif\")\n",
    "asset_wealth_2020_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Asset-Wealth-1912m_0_08_RWA_2020.tif\")\n",
    "\n",
    "asset_wealth_2016_shp = asset_wealth_2016_shp[asset_wealth_2016_shp[\"pixel_value\"]<3]\n",
    "asset_wealth_2017_shp = asset_wealth_2017_shp[asset_wealth_2017_shp[\"pixel_value\"]<3]\n",
    "asset_wealth_2018_shp = asset_wealth_2018_shp[asset_wealth_2018_shp[\"pixel_value\"]<3]\n",
    "asset_wealth_2019_shp = asset_wealth_2019_shp[asset_wealth_2019_shp[\"pixel_value\"]<3]\n",
    "asset_wealth_2020_shp = asset_wealth_2020_shp[asset_wealth_2020_shp[\"pixel_value\"]<3]\n",
    "\n",
    "village_asset_wealth_2016 = compute_administrative_metric(asset_wealth_2016_shp, \"village\")\n",
    "village_asset_wealth_2017 = compute_administrative_metric(asset_wealth_2017_shp, \"village\")\n",
    "village_asset_wealth_2018 = compute_administrative_metric(asset_wealth_2018_shp, \"village\")\n",
    "village_asset_wealth_2019 = compute_administrative_metric(asset_wealth_2019_shp, \"village\")\n",
    "village_asset_wealth_2020 = compute_administrative_metric(asset_wealth_2020_shp, \"village\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas AI spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spending\n",
    "\n",
    "spending_2016_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Spending-1912m_0_12_RWA_2016.tif\")\n",
    "spending_2017_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Spending-1912m_0_12_RWA_2017.tif\")\n",
    "spending_2018_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Spending-1912m_0_12_RWA_2018.tif\")\n",
    "spending_2019_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Spending-1912m_0_12_RWA_2019.tif\")\n",
    "spending_2020_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/atlas_ai_files/Rwanda_Spending-1912m_0_12_RWA_2020.tif\")\n",
    "\n",
    "spending_2016_shp = spending_2016_shp[spending_2016_shp[\"pixel_value\"]<1000]\n",
    "spending_2017_shp = spending_2017_shp[spending_2017_shp[\"pixel_value\"]<1000]\n",
    "spending_2018_shp = spending_2018_shp[spending_2018_shp[\"pixel_value\"]<1000]\n",
    "spending_2019_shp = spending_2019_shp[spending_2019_shp[\"pixel_value\"]<1000]\n",
    "spending_2020_shp = spending_2020_shp[spending_2020_shp[\"pixel_value\"]<1000]\n",
    "\n",
    "village_spending_2016 = compute_administrative_metric(spending_2016_shp, \"village\")\n",
    "village_spending_2017 = compute_administrative_metric(spending_2017_shp, \"village\")\n",
    "village_spending_2018 = compute_administrative_metric(spending_2018_shp, \"village\")\n",
    "village_spending_2019 = compute_administrative_metric(spending_2019_shp, \"village\")\n",
    "village_spending_2020 = compute_administrative_metric(spending_2020_shp, \"village\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree of Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree of Urbanization\n",
    "\n",
    "urban_2010_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_SMOD_E2010_GLOBE_R2023A_54009_1000_V1_0.tif\")\n",
    "urban_2015_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_SMOD_E2015_GLOBE_R2023A_54009_1000_V1_0.tif\")\n",
    "urban_2020_shp = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_SMOD_E2020_GLOBE_R2023A_54009_1000_V1_0.tif\")\n",
    "\n",
    "urban_2010_shp = urban_2010_shp[urban_2010_shp[\"pixel_value\"]>0]\n",
    "urban_2015_shp = urban_2015_shp[urban_2015_shp[\"pixel_value\"]>0]\n",
    "urban_2020_shp = urban_2020_shp[urban_2020_shp[\"pixel_value\"]>0]\n",
    "\n",
    "village_urban_2010 = compute_administrative_metric(urban_2010_shp, \"village\", summary_method=\"mode\")\n",
    "village_urban_2015 = compute_administrative_metric(urban_2015_shp, \"village\", summary_method=\"mode\")\n",
    "village_urban_2020 = compute_administrative_metric(urban_2020_shp, \"village\", summary_method=\"mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_height_2018 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_built_H_2018.tif\")\n",
    "building_height_2018 = building_height_2018[building_height_2018[\"pixel_value\"]>0]\n",
    "\n",
    "village_building_height_2018 = compute_administrative_metric(building_height_2018, \"village\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building_volume_2010 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_Built_V_2010.tif\")\n",
    "# building_volume_2015 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_Built_V_2015.tif\")\n",
    "# building_volume_2020 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/european_commision/GHS_Built_V_2020.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# village_building_volume_2010 = compute_administrative_metric(building_volume_2010, \"village\")\n",
    "# village_building_volume_2015 = compute_administrative_metric(building_volume_2015, \"village\")\n",
    "# village_building_volume_2020 = compute_administrative_metric(building_volume_2020, \"village\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# village_building_volume_2010.to_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2010.pkl\")\n",
    "# village_building_volume_2015.to_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2015.pkl\")\n",
    "# village_building_volume_2020.to_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2020.pkl\")\n",
    "\n",
    "# How to read\n",
    "# a = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2020.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_building_volume_2010 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2010.pkl\")\n",
    "village_building_volume_2015 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2015.pkl\")\n",
    "village_building_volume_2020 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/european_commision/village_building_volume_2020.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population_grid_2010 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/Rwanda_100m_Population/RWA_pph_2010_adj_v2.tif\")\n",
    "# population_grid_2015 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/Rwanda_100m_Population/RWA_pph_2015_adj_v2.tif\")\n",
    "# population_grid_2020 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/Rwanda_100m_Population/RWA_pph_2020_adj_v2.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# village_population_grid_2010 = compute_administrative_metric(population_grid_2010, \"village\")\n",
    "# village_population_grid_2015 = compute_administrative_metric(population_grid_2015, \"village\")\n",
    "# village_population_grid_2020 = compute_administrative_metric(population_grid_2020, \"village\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # population\n",
    "# population_2012 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2012.tif\")\n",
    "# population_2013 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2013.tif\")\n",
    "# population_2014 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2014.tif\")\n",
    "# population_2015 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2015.tif\")\n",
    "# population_2016 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2016.tif\")\n",
    "# population_2017 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2017.tif\")\n",
    "# population_2018 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2018.tif\")\n",
    "# population_2019 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2019.tif\")\n",
    "# population_2020 = parallel_clip_large_tif(\"/gypsum/eguide/projects/ce8760/rwanda_population/rwa_ppp_2020.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# village_population_2012 = compute_administrative_metric(population_2012, \"village\")\n",
    "# village_population_2013 = compute_administrative_metric(population_2013, \"village\")\n",
    "# village_population_2014 = compute_administrative_metric(population_2014, \"village\")\n",
    "# village_population_2015 = compute_administrative_metric(population_2015, \"village\")\n",
    "# village_population_2016 = compute_administrative_metric(population_2016, \"village\")\n",
    "# village_population_2017 = compute_administrative_metric(population_2017, \"village\")\n",
    "# village_population_2018 = compute_administrative_metric(population_2018, \"village\")\n",
    "# village_population_2019 = compute_administrative_metric(population_2019, \"village\")\n",
    "# village_population_2020 = compute_administrative_metric(population_2020, \"village\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# village_population_2012.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2012.pkl\")\n",
    "# village_population_2013.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2013.pkl\")\n",
    "# village_population_2014.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2014.pkl\")\n",
    "# village_population_2015.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2015.pkl\")\n",
    "# village_population_2016.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2016.pkl\")\n",
    "# village_population_2017.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2017.pkl\")\n",
    "# village_population_2018.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2018.pkl\")\n",
    "# village_population_2019.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2019.pkl\")\n",
    "# village_population_2020.to_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2020.pkl\")\n",
    "\n",
    "\n",
    "village_population_2012 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2012.pkl\")\n",
    "village_population_2013 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2013.pkl\")\n",
    "village_population_2014 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2014.pkl\")\n",
    "village_population_2015 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2015.pkl\")\n",
    "village_population_2016 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2016.pkl\")\n",
    "village_population_2017 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2017.pkl\")\n",
    "village_population_2018 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2018.pkl\")\n",
    "village_population_2019 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2019.pkl\")\n",
    "village_population_2020 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/population/village_population_2020.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_combined_data(pickle_path, connection_type):\n",
    "    df = pd.read_pickle(pickle_path)\n",
    "    if connection_type == \"Residential\":\n",
    "        df = df[df[\"connection_type\"] == \"Residential\"]\n",
    "    else:\n",
    "        df = df[df[\"connection_type\"] != \"Residential\"]\n",
    "    df['transaction_date'] = pd.to_datetime(df['transaction_date'], errors='coerce')\n",
    "    df['installation_date'] = pd.to_datetime(df['installation_date'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def preprocess_meter_locations(df):\n",
    "    grouped = df.groupby([\n",
    "        df[\"meter_serial_number\"],\n",
    "        df[\"connection_type\"],\n",
    "        df['transaction_date'].dt.year\n",
    "    ]).agg({\n",
    "        \"geometry\": \"first\",\n",
    "        \"sector_id\": \"first\",\n",
    "        \"cell_id\": \"first\",\n",
    "        \"village_id\": \"first\"\n",
    "    }).reset_index()\n",
    "    return grouped.groupby(\"meter_serial_number\")[[\"geometry\"]].first().reset_index(), grouped\n",
    "\n",
    "def extract_coords(geom):\n",
    "    if geom.geom_type == 'Polygon':\n",
    "        return geom.centroid.coords[0]\n",
    "    elif geom.geom_type == 'Point':\n",
    "        return geom.coords[0]\n",
    "    elif geom.geom_type == 'MultiPolygon':\n",
    "        largest_polygon = max(geom.geoms, key=lambda p: p.area)\n",
    "        return largest_polygon.centroid.coords[0]\n",
    "    elif geom.geom_type == 'MultiPoint':\n",
    "        return geom.geoms[0].coords[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported geometry type: {geom.geom_type}\")\n",
    "\n",
    "def build_ckdtree_from_geoms(gdf):\n",
    "    coords = gdf['geometry'].apply(extract_coords)\n",
    "    return cKDTree(list(coords))\n",
    "\n",
    "def compute_nearest_distances(src_points, tree):\n",
    "    src_coords = np.array([[pt.x, pt.y] for pt in src_points])\n",
    "    distances, _ = tree.query(src_coords, k=1)\n",
    "    return [geodesic((0, 0), (0, d)).kilometers for d in distances]\n",
    "\n",
    "def create_distance_summary(df, meter_df, column_name):\n",
    "    df = pd.merge(df, meter_df[[\"meter_serial_number\", column_name]], on=\"meter_serial_number\", how=\"left\")\n",
    "    return df.groupby([\"village_id\", \"transaction_date\"])[column_name].median().reset_index()\n",
    "\n",
    "def extract_min_distance_column(df, tree, column_name):\n",
    "    def extract(row):\n",
    "        point = row['geometry'].coords[0]\n",
    "        distance, _ = tree.query(point)\n",
    "        return geodesic((0, 0), (0, distance)).kilometers\n",
    "    df[column_name] = df.apply(extract, axis=1)\n",
    "    return df\n",
    "\n",
    "def extract_tariffs_or_consumption(path, column_name):\n",
    "    df = pd.read_csv(path).dropna()\n",
    "    df = df.melt(id_vars=\"administrative_id\", var_name=\"transaction_date\", value_name=column_name)\n",
    "    df.columns = [\"village_id\", \"date\", column_name]\n",
    "    df = df[~df[\"date\"].isin([2012, 2020, \"geometry\"])]\n",
    "    return df.reset_index(drop=True).iloc[:-1]\n",
    "\n",
    "def join_annual_tables(table_list):\n",
    "    for df in table_list:\n",
    "        df[\"date\"] = str(df[\"date\"].iloc[0])\n",
    "        df.drop(columns=[\"geometry\"], inplace=True)\n",
    "    df_merged = table_list[0]\n",
    "    for df in table_list[1:]:\n",
    "        df_merged = pd.merge(df_merged, df, on=[\"Village_ID\", \"date\", \"pixel_value\"], how=\"outer\")\n",
    "    return df_merged\n",
    "\n",
    "def finalize_feature(df, column_name):\n",
    "    df.columns = [\"village_id\", column_name, \"year\"]\n",
    "    df[\"year\"] = df[\"year\"].astype(\"str\")\n",
    "    return df\n",
    "\n",
    "def merge_features(final_df, *features):\n",
    "    for feature_df in features:\n",
    "        final_df = pd.merge(final_df, feature_df, on=[\"village_id\", \"year\"], how=\"outer\")\n",
    "    return final_df\n",
    "\n",
    "def generate_final_df(connection_type, base_path):\n",
    "    # Step 1: Load data\n",
    "    combined = load_combined_data(os.path.join(base_path, \"combined_data.pkl\"), connection_type)\n",
    "    meters_df, test_combined = preprocess_meter_locations(combined)\n",
    "\n",
    "    # Step 2: Roads\n",
    "    roads = gpd.read_file(os.path.join(base_path, \"rwa_road/rwa_road.shp\")).to_crs(\"EPSG:4326\")\n",
    "    roads = roads[roads[\"type\"].isin([\"Primary Route\", \"Secondary Route\"])]\n",
    "    road_points = [pt for line in roads.geometry for pt in [line.interpolate(i / 1000, normalized=True) for i in range(1001)]]\n",
    "    tree = cKDTree([[pt.x, pt.y] for pt in road_points])\n",
    "    meters_df['distance_to_nearest_road'] = compute_nearest_distances(meters_df.geometry, tree)\n",
    "\n",
    "    village_distance_to_nearest_road = create_distance_summary(test_combined, meters_df, \"distance_to_nearest_road\")\n",
    "\n",
    "    # Step 3: Other amenities\n",
    "    amenities = {\n",
    "        \"market\": \"open_street_map/marketplace.geojson\",\n",
    "        \"busstation\": \"open_street_map/bus_station.geojson\",\n",
    "        \"schools\": \"open_street_map/school_export.geojson\",\n",
    "        \"banks\": \"open_street_map/banks.geojson\"\n",
    "    }\n",
    "    for key, path in amenities.items():\n",
    "        gdf = gpd.read_file(os.path.join(base_path, path)).to_crs(\"EPSG:4326\")\n",
    "        tree = build_ckdtree_from_geoms(gdf)\n",
    "        test_combined = extract_min_distance_column(test_combined, tree, f\"distance_{key}\")\n",
    "\n",
    "    village_distance_to_market = test_combined.groupby([\"village_id\", \"transaction_date\"])[\"distance_market\"].median().reset_index()\n",
    "    village_distance_to_busstation = test_combined.groupby([\"village_id\", \"transaction_date\"])[\"distance_busstation\"].median().reset_index()\n",
    "    village_distance_to_school = test_combined.groupby([\"village_id\", \"transaction_date\"])[\"distance_schools\"].median().reset_index()\n",
    "    village_distance_to_banks = test_combined.groupby([\"village_id\", \"transaction_date\"])[\"distance_banks\"].median().reset_index()\n",
    "\n",
    "    # Step 4: Assemble distance features\n",
    "    for df in [village_distance_to_market, village_distance_to_busstation, village_distance_to_nearest_road, village_distance_to_school, village_distance_to_banks]:\n",
    "        df[\"transaction_date\"] = df[\"transaction_date\"].astype(str)\n",
    "\n",
    "    final_df = village_distance_to_market \\\n",
    "        .merge(village_distance_to_busstation, on=[\"village_id\", \"transaction_date\"]) \\\n",
    "        .merge(village_distance_to_nearest_road, on=[\"village_id\", \"transaction_date\"]) \\\n",
    "        .merge(village_distance_to_school, on=[\"village_id\", \"transaction_date\"]) \\\n",
    "        .merge(village_distance_to_banks, on=[\"village_id\", \"transaction_date\"])\n",
    "\n",
    "    final_df = final_df.rename(columns={\"transaction_date\": \"year\"})\n",
    "    final_df[\"year\"] = final_df[\"year\"].astype(str)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = generate_final_df(connection_type=\"Residential\", base_path=\"/gypsum/eguide/projects/ce8760\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/gypsum/eguide/projects/ce8760/res_final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_res_final_df = generate_final_df(connection_type=\"Non Residential\", base_path=\"/gypsum/eguide/projects/ce8760\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_res_final_df.to_csv(\"/gypsum/eguide/projects/ce8760/non_res_final_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asset Wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with asset wealth\n",
    "village_asset_wealth_2016[\"date\"] = \"2016\"\n",
    "village_asset_wealth_2017[\"date\"] = \"2017\"\n",
    "village_asset_wealth_2018[\"date\"] = \"2018\"\n",
    "village_asset_wealth_2019[\"date\"] = \"2019\"\n",
    "village_asset_wealth_2020[\"date\"] = \"2020\"\n",
    "\n",
    "village_asset_wealth_2016.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_asset_wealth_2017.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_asset_wealth_2018.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_asset_wealth_2019.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_asset_wealth_2020.drop(columns = [\"geometry\"], inplace=True)\n",
    "\n",
    "village_asset_wealth = pd.merge(pd.merge(pd.merge(pd.merge(village_asset_wealth_2016, \n",
    "                               village_asset_wealth_2017, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_asset_wealth_2018, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_asset_wealth_2019, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_asset_wealth_2020, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"\n",
    ")\n",
    "village_asset_wealth.columns = [\"village_id\", \"asset_wealth\", \"year\"]\n",
    "\n",
    "village_asset_wealth[\"year\"] = village_asset_wealth[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, village_asset_wealth, how=\"left\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with asset wealth\n",
    "village_spending_2016[\"date\"] = \"2016\"\n",
    "village_spending_2017[\"date\"] = \"2017\"\n",
    "village_spending_2018[\"date\"] = \"2018\"\n",
    "village_spending_2019[\"date\"] = \"2019\"\n",
    "village_spending_2020[\"date\"] = \"2020\"\n",
    "\n",
    "village_spending_2016.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_spending_2017.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_spending_2018.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_spending_2019.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_spending_2020.drop(columns = [\"geometry\"], inplace=True)\n",
    "\n",
    "village_spending = pd.merge(pd.merge(pd.merge(pd.merge(village_spending_2016, \n",
    "                               village_spending_2017, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_spending_2018, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_spending_2019, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_spending_2020, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"\n",
    ")\n",
    "village_spending.columns = [\"village_id\", \"spending\", \"year\"]\n",
    "\n",
    "village_spending[\"year\"] = village_spending[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, village_spending, how=\"left\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_population_2012[\"date\"] = \"2012\"\n",
    "village_population_2013[\"date\"] = \"2013\"\n",
    "village_population_2014[\"date\"] = \"2014\"\n",
    "village_population_2015[\"date\"] = \"2015\"\n",
    "village_population_2016[\"date\"] = \"2016\"\n",
    "village_population_2017[\"date\"] = \"2017\"\n",
    "village_population_2018[\"date\"] = \"2018\"\n",
    "village_population_2019[\"date\"] = \"2019\"\n",
    "village_population_2020[\"date\"] = \"2020\"\n",
    "\n",
    "village_population_2012.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2013.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2014.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2015.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2016.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2017.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2018.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2019.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_population_2020.drop(columns = [\"geometry\"], inplace=True)\n",
    "\n",
    "village_population = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(village_population_2012, \n",
    "                               village_population_2013, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2014, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2015, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2016, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2017, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2018, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2019, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_population_2020, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"\n",
    ")\n",
    "village_population.columns = [\"village_id\", \"population\", \"year\"]\n",
    "\n",
    "village_population[\"year\"] = village_population[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, village_population, how=\"outer\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_urban_2010[\"date\"] = \"2010\"\n",
    "village_urban_2015[\"date\"] = \"2015\"\n",
    "village_urban_2020[\"date\"] = \"2020\"\n",
    "\n",
    "village_urban_2010.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_urban_2015.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_urban_2020.drop(columns = [\"geometry\"], inplace=True)\n",
    "\n",
    "urbanization = pd.merge(pd.merge(village_urban_2010, \n",
    "                               village_urban_2015, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_urban_2020, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\",\n",
    ")\n",
    "urbanization.columns = [\"village_id\", \"urbanization\", \"year\"]\n",
    "\n",
    "urbanization[\"year\"] = urbanization[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, urbanization, how=\"outer\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_building_volume_2010[\"date\"] = \"2010\"\n",
    "village_building_volume_2015[\"date\"] = \"2015\"\n",
    "village_building_volume_2020[\"date\"] = \"2020\"\n",
    "\n",
    "village_building_volume_2010.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_building_volume_2015.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_building_volume_2020.drop(columns = [\"geometry\"], inplace=True)\n",
    "\n",
    "building_volume = pd.merge(pd.merge(village_building_volume_2010, \n",
    "                               village_building_volume_2015, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\"),\n",
    "                               village_building_volume_2020, on=[\"Village_ID\", \"date\", \"pixel_value\"],how=\"outer\",\n",
    ")\n",
    "building_volume.columns = [\"village_id\", \"building_volume\", \"year\"]\n",
    "\n",
    "building_volume[\"year\"] = building_volume[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, building_volume, how=\"outer\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_building_height_2018.drop(columns = [\"geometry\"], inplace=True)\n",
    "village_building_height_2018.columns = [\"village_id\", \"building_height\"]\n",
    "final_df = pd.merge(final_df, village_building_height_2018, how=\"left\", on = [\"village_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = pd.read_csv(\"/gypsum/eguide/projects/ce8760/data/landcover/landcover.csv\")\n",
    "landcover[\"year\"] = landcover[\"year\"].astype(str)\n",
    "landcover[\"village_id\"] = landcover[\"village_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_2013 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/data/landcover/df_2013.pkl\")\n",
    "landcover_2014 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/data/landcover/df_2014.pkl\")\n",
    "landcover_2015 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/data/landcover/df_2015.pkl\")\n",
    "landcover_2016 = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/data/landcover/df_2016.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_2013.columns = landcover.columns\n",
    "landcover_2014.columns = landcover.columns\n",
    "landcover_2015.columns = landcover.columns\n",
    "landcover_2016.columns = landcover.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover = pd.concat([landcover_2013, landcover_2014, landcover_2015, landcover_2016, landcover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 148150 entries, 0 to 88889\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   village_id            148150 non-null  object \n",
      " 1   cropland_proportion   148150 non-null  float64\n",
      " 2   builtarea_proportion  148150 non-null  float64\n",
      " 3   rangeland_proportion  148150 non-null  float64\n",
      " 4   year                  148150 non-null  object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "landcover.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover[\"year\"] = landcover[\"year\"].astype(\"str\")\n",
    "landcover[\"village_id\"] = landcover[\"village_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.drop(columns = [\"cropland_proportion\", \"builtarea_proportion\", \"rangeland_proportion\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"year\"] = final_df[\"year\"].astype(\"str\")\n",
    "final_df[\"village_id\"] = final_df[\"village_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, landcover, how=\"outer\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village_id</th>\n",
       "      <th>year</th>\n",
       "      <th>distance_market</th>\n",
       "      <th>distance_busstation</th>\n",
       "      <th>distance_to_nearest_road</th>\n",
       "      <th>distance_schools</th>\n",
       "      <th>distance_banks</th>\n",
       "      <th>asset_wealth</th>\n",
       "      <th>spending</th>\n",
       "      <th>population</th>\n",
       "      <th>urbanization</th>\n",
       "      <th>building_volume</th>\n",
       "      <th>building_height</th>\n",
       "      <th>cropland_proportion</th>\n",
       "      <th>builtarea_proportion</th>\n",
       "      <th>rangeland_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11010102</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.765208</td>\n",
       "      <td>0.248803</td>\n",
       "      <td>0.172175</td>\n",
       "      <td>0.443753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.252640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.085509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11010102</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.988930</td>\n",
       "      <td>0.767398</td>\n",
       "      <td>0.248803</td>\n",
       "      <td>0.172175</td>\n",
       "      <td>0.439669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.667900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.085509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11010102</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.988848</td>\n",
       "      <td>0.765208</td>\n",
       "      <td>0.249891</td>\n",
       "      <td>0.173555</td>\n",
       "      <td>0.438713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.239548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.085509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11010102</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.765208</td>\n",
       "      <td>0.249891</td>\n",
       "      <td>0.173555</td>\n",
       "      <td>0.442250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251.027534</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50853.0</td>\n",
       "      <td>5.085509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11010102</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.988191</td>\n",
       "      <td>0.765208</td>\n",
       "      <td>0.249891</td>\n",
       "      <td>0.173555</td>\n",
       "      <td>0.442250</td>\n",
       "      <td>1.070581</td>\n",
       "      <td>6.413167</td>\n",
       "      <td>256.711594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.085509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177775</th>\n",
       "      <td>57150501</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300282</td>\n",
       "      <td>0.158434</td>\n",
       "      <td>0.007784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177776</th>\n",
       "      <td>57150502</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214361</td>\n",
       "      <td>0.196575</td>\n",
       "      <td>0.150272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177777</th>\n",
       "      <td>57150503</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209166</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.177291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177778</th>\n",
       "      <td>57150504</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.050098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177779</th>\n",
       "      <td>57150505</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.085686</td>\n",
       "      <td>0.083606</td>\n",
       "      <td>0.336095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177780 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       village_id  year  distance_market  distance_busstation  \\\n",
       "0        11010102  2012         0.988930             0.765208   \n",
       "1        11010102  2013         0.988930             0.767398   \n",
       "2        11010102  2014         0.988848             0.765208   \n",
       "3        11010102  2015         0.988191             0.765208   \n",
       "4        11010102  2016         0.988191             0.765208   \n",
       "...           ...   ...              ...                  ...   \n",
       "177775   57150501  2022              NaN                  NaN   \n",
       "177776   57150502  2022              NaN                  NaN   \n",
       "177777   57150503  2022              NaN                  NaN   \n",
       "177778   57150504  2022              NaN                  NaN   \n",
       "177779   57150505  2022              NaN                  NaN   \n",
       "\n",
       "        distance_to_nearest_road  distance_schools  distance_banks  \\\n",
       "0                       0.248803          0.172175        0.443753   \n",
       "1                       0.248803          0.172175        0.439669   \n",
       "2                       0.249891          0.173555        0.438713   \n",
       "3                       0.249891          0.173555        0.442250   \n",
       "4                       0.249891          0.173555        0.442250   \n",
       "...                          ...               ...             ...   \n",
       "177775                       NaN               NaN             NaN   \n",
       "177776                       NaN               NaN             NaN   \n",
       "177777                       NaN               NaN             NaN   \n",
       "177778                       NaN               NaN             NaN   \n",
       "177779                       NaN               NaN             NaN   \n",
       "\n",
       "        asset_wealth  spending  population  urbanization  building_volume  \\\n",
       "0                NaN       NaN  256.252640           NaN              NaN   \n",
       "1                NaN       NaN  257.667900           NaN              NaN   \n",
       "2                NaN       NaN  265.239548           NaN              NaN   \n",
       "3                NaN       NaN  251.027534          30.0          50853.0   \n",
       "4           1.070581  6.413167  256.711594           NaN              NaN   \n",
       "...              ...       ...         ...           ...              ...   \n",
       "177775           NaN       NaN         NaN           NaN              NaN   \n",
       "177776           NaN       NaN         NaN           NaN              NaN   \n",
       "177777           NaN       NaN         NaN           NaN              NaN   \n",
       "177778           NaN       NaN         NaN           NaN              NaN   \n",
       "177779           NaN       NaN         NaN           NaN              NaN   \n",
       "\n",
       "        building_height  cropland_proportion  builtarea_proportion  \\\n",
       "0              5.085509                  NaN                   NaN   \n",
       "1              5.085509             0.000000              1.000000   \n",
       "2              5.085509             0.000000              1.000000   \n",
       "3              5.085509             0.000000              1.000000   \n",
       "4              5.085509             0.000000              1.000000   \n",
       "...                 ...                  ...                   ...   \n",
       "177775              NaN             0.300282              0.158434   \n",
       "177776              NaN             0.214361              0.196575   \n",
       "177777              NaN             0.209166              0.133858   \n",
       "177778              NaN             0.067908              0.430303   \n",
       "177779              NaN             0.085686              0.083606   \n",
       "\n",
       "        rangeland_proportion  \n",
       "0                        NaN  \n",
       "1                   0.000000  \n",
       "2                   0.000000  \n",
       "3                   0.000000  \n",
       "4                   0.000000  \n",
       "...                      ...  \n",
       "177775              0.007784  \n",
       "177776              0.150272  \n",
       "177777              0.177291  \n",
       "177778              0.050098  \n",
       "177779              0.336095  \n",
       "\n",
       "[177780 rows x 16 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_pickle(\"residential_customers_panel_10yr_above.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Residential Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonresidential_annual_consumption_path = \"../final_data/final_reg_data/annual_nonresidential_consumption_10yr_above/village/median/annual_median.csv\"\n",
    "noresidential_annual_tariff_path =  \"../final_data/final_reg_data/annual_nonresidential_tariffs_10yr_above/village/median/annual_median.csv\"\n",
    "consumption_non_res_df = extract_consumption_tariffs(nonresidential_annual_consumption_path, \"consumption\")\n",
    "tarrif_non_res_df = extract_consumption_tariffs(noresidential_annual_tariff_path, \"tariff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village_id</th>\n",
       "      <th>date</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2012</td>\n",
       "      <td>123.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2013</td>\n",
       "      <td>408.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2014</td>\n",
       "      <td>462.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2015</td>\n",
       "      <td>368.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2016</td>\n",
       "      <td>368.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2016</td>\n",
       "      <td>229.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2017</td>\n",
       "      <td>217.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2018</td>\n",
       "      <td>193.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2019</td>\n",
       "      <td>309.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2020</td>\n",
       "      <td>106.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3465 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      village_id  date consumption\n",
       "0       11010107  2012       123.2\n",
       "1       11010107  2013      408.65\n",
       "2       11010107  2014      462.25\n",
       "3       11010107  2015       368.4\n",
       "4       11010107  2016       368.9\n",
       "...          ...   ...         ...\n",
       "3844    57100512  2016       229.6\n",
       "3845    57100512  2017       217.7\n",
       "3846    57100512  2018      193.65\n",
       "3847    57100512  2019       309.5\n",
       "3848    57100512  2020       106.9\n",
       "\n",
       "[3465 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption_non_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_pickle(\"/gypsum/eguide/projects/ce8760/combined_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'Non Residential'], dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = combined_data[combined_data[\"connection_type\"] != \"Residential\"]\n",
    "combined_data.connection_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['transaction_date'] = pd.to_datetime(combined_data['transaction_date'], format='mixed')\n",
    "combined_data['installation_date'] = pd.to_datetime(combined_data['installation_date'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the earliest installation date per administrative region\n",
    "earliest_dates = combined_data.groupby(\"village_id\")['installation_date'].min()\n",
    "combined_data = combined_data.merge(earliest_dates.rename('earliest_installation'), on=\"village_id\")\n",
    "combined_data = combined_data[combined_data['installation_date'] > combined_data['earliest_installation'] + pd.DateOffset(years=10)]\n",
    "# combined_data = combined_data[(combined_data['installation_date'] > combined_data['earliest_installation'] + pd.DateOffset(years=5)) &\n",
    "#         (combined_data['installation_date'] <= combined_data['earliest_installation'] + pd.DateOffset(years=10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = combined_data.groupby([combined_data[\"meter_serial_number\"], combined_data[\"connection_type\"], \n",
    "                                       combined_data['transaction_date'].dt.year]).agg({\n",
    "    \"geometry\": \"first\",\n",
    "    \"sector_id\": \"first\",\n",
    "    \"cell_id\": \"first\",\n",
    "    \"village_id\": \"first\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_location = test_combined.groupby(\"meter_serial_number\")[[\"geometry\"]].first().reset_index()\n",
    "meters_location = gpd.GeoDataFrame(meter_location, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'rwa_roads' is your GeoDataFrame containing the road geometries\n",
    "road_points = []\n",
    "for road in rwa_roads.geometry:\n",
    "    road_points.extend(line_to_points(road, num_points=1000))  # Adjust num_points as needed\n",
    "\n",
    "# Convert the list of Points into an array of [x, y] for cKDTree\n",
    "road_points_array = np.array([[point.x, point.y] for point in road_points])\n",
    "\n",
    "# Build the cKDTree for efficient nearest-neighbor queries\n",
    "tree = cKDTree(road_points_array)\n",
    "\n",
    "# Assuming 'meter_location' is your GeoDataFrame containing the meter point geometries\n",
    "# Convert meter locations into an array of [x, y] for querying the cKDTree\n",
    "meter_points_array = np.array([[point.x, point.y] for point in meter_location.geometry])\n",
    "\n",
    "# Query the cKDTree for the nearest road point to each meter location\n",
    "distances, indices = tree.query(meter_points_array, k=1)\n",
    "\n",
    "distances_in_km = []\n",
    "\n",
    "for distance in distances:\n",
    "    distances_in_km.append(geodesic((0, 0), (0, distance)).kilometers)\n",
    "    \n",
    "\n",
    "# Add the distances as a new column to the meter_location GeoDataFrame\n",
    "meter_location['distance_to_nearest_road'] = np.array(distances_in_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined = pd.merge(test_combined, meter_location[[\"meter_serial_number\", \"distance_to_nearest_road\"]], \n",
    "                   how=\"left\", on=\"meter_serial_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_distance_to_nearest_road = test_combined.groupby([\"village_id\", \"transaction_date\"]).agg({\n",
    "    \"distance_to_nearest_road\": \"median\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cKDTree using the shop geometries\n",
    "tree = cKDTree(marketplace['geometry'].apply(lambda x: x.centroid.coords[0] if x.geom_type == 'Polygon' else x.coords[0]).tolist())\n",
    "\n",
    "# Function to find the distance to the nearest shop\n",
    "def find_nearest_shop_distance(row, tree):\n",
    "    point = row['geometry'].coords[0]\n",
    "    distance, _ = tree.query(point)\n",
    "\n",
    "    # Convert distance from degrees to kilometers using Haversine formula\n",
    "    distance_in_km = geodesic((0, 0), (0, distance)).kilometers\n",
    "    \n",
    "    return distance_in_km\n",
    "\n",
    "\n",
    "# Apply the function to create a new 'distance' column in df1\n",
    "test_combined['distance_market'] = test_combined.apply(lambda row: find_nearest_shop_distance(row, tree), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_distance_to_market = test_combined.groupby([\"village_id\", \"transaction_date\"]).agg({\n",
    "    \"distance_market\": \"median\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined[\"distance_busstation\"] = test_combined.apply(lambda row: find_nearest_shop_distance(row, bus_tree), axis=1)\n",
    "# test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "village_distance_to_busstation = test_combined.groupby([\"village_id\", \"transaction_date\"]).agg({\n",
    "    \"distance_busstation\": \"median\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined[\"distance_schools\"] = test_combined.apply(lambda row: find_nearest_shop_distance(row, school_tree), axis=1)\n",
    "\n",
    "village_distance_to_school = test_combined.groupby([\"village_id\", \"transaction_date\"]).agg({\n",
    "    \"distance_schools\": \"median\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined[\"distance_banks\"] = test_combined.apply(lambda row: find_nearest_shop_distance(row, bank_tree), axis=1)\n",
    "\n",
    "village_distance_to_banks = test_combined.groupby([\"village_id\", \"transaction_date\"]).agg({\n",
    "    \"distance_banks\": \"median\"\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_non_res_df = pd.merge(consumption_non_res_df, tarrif_non_res_df, right_on=[\"village_id\", \"date\"], left_on=[\"village_id\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_non_res_df['date'] = consumption_non_res_df['date'].astype('object')\n",
    "consumption_non_res_df['village_id'] = consumption_non_res_df['village_id'].astype('str')\n",
    "tarrif_non_res_df['date'] = tarrif_non_res_df['date'].astype('object')\n",
    "tarrif_non_res_df['village_id'] = tarrif_non_res_df['village_id'].astype('str')\n",
    "village_distance_to_market['transaction_date'] = village_distance_to_market['transaction_date'].astype('str')\n",
    "village_distance_to_busstation['transaction_date'] = village_distance_to_busstation['transaction_date'].astype('str')\n",
    "village_distance_to_nearest_road['transaction_date'] = village_distance_to_nearest_road['transaction_date'].astype('str')\n",
    "village_distance_to_school['transaction_date'] = village_distance_to_school['transaction_date'].astype('str')\n",
    "village_distance_to_banks['transaction_date'] = village_distance_to_banks['transaction_date'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_non_res_df = pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(consumption_non_res_df, \n",
    "                    village_distance_to_market, left_on=[\"village_id\", \"date\"],\n",
    "                    right_on=[\"village_id\", \"transaction_date\"]).drop(columns=[\"transaction_date\"]),\n",
    "                    village_distance_to_busstation, left_on=[\"village_id\", \"date\"],\n",
    "                     right_on=[\"village_id\", \"transaction_date\"]).drop(columns=[\"transaction_date\"]),\n",
    "    village_distance_to_nearest_road, left_on=[\"village_id\", \"date\"],\n",
    "                     right_on=[\"village_id\", \"transaction_date\"]).drop(columns=[\"transaction_date\"]),\n",
    "    village_distance_to_school, left_on=[\"village_id\", \"date\"],\n",
    "                     right_on=[\"village_id\", \"transaction_date\"]).drop(columns=[\"transaction_date\"]),\n",
    "    village_distance_to_banks, left_on=[\"village_id\", \"date\"],\n",
    "                     right_on=[\"village_id\", \"transaction_date\"]).drop(columns=[\"transaction_date\"])\n",
    "                     \n",
    "\n",
    "final_non_res_df = final_non_res_df.rename(columns={\"date\":\"year\"})\n",
    "final_non_res_df[\"year\"] = final_non_res_df[\"year\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village_id</th>\n",
       "      <th>year</th>\n",
       "      <th>consumption</th>\n",
       "      <th>tariff</th>\n",
       "      <th>distance_market</th>\n",
       "      <th>distance_busstation</th>\n",
       "      <th>distance_to_nearest_road</th>\n",
       "      <th>distance_schools</th>\n",
       "      <th>distance_banks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2012</td>\n",
       "      <td>123.2</td>\n",
       "      <td>16525.0</td>\n",
       "      <td>1.072830</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.026218</td>\n",
       "      <td>0.488517</td>\n",
       "      <td>0.201774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2013</td>\n",
       "      <td>408.65</td>\n",
       "      <td>54871.5</td>\n",
       "      <td>1.072906</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.488534</td>\n",
       "      <td>0.201751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2014</td>\n",
       "      <td>462.25</td>\n",
       "      <td>62070.0</td>\n",
       "      <td>1.072906</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>0.488534</td>\n",
       "      <td>0.201751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2015</td>\n",
       "      <td>368.4</td>\n",
       "      <td>55941.5</td>\n",
       "      <td>1.072829</td>\n",
       "      <td>0.518942</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.488617</td>\n",
       "      <td>0.201498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11010107</td>\n",
       "      <td>2016</td>\n",
       "      <td>368.9</td>\n",
       "      <td>67198.0</td>\n",
       "      <td>1.072828</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.488551</td>\n",
       "      <td>0.201729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2016</td>\n",
       "      <td>229.6</td>\n",
       "      <td>42088.5</td>\n",
       "      <td>1.021832</td>\n",
       "      <td>0.461342</td>\n",
       "      <td>10.601017</td>\n",
       "      <td>1.002348</td>\n",
       "      <td>0.799732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2017</td>\n",
       "      <td>217.7</td>\n",
       "      <td>41186.0</td>\n",
       "      <td>1.053419</td>\n",
       "      <td>0.621131</td>\n",
       "      <td>10.685755</td>\n",
       "      <td>0.961046</td>\n",
       "      <td>0.831267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2018</td>\n",
       "      <td>193.65</td>\n",
       "      <td>37294.5</td>\n",
       "      <td>1.024816</td>\n",
       "      <td>0.621131</td>\n",
       "      <td>10.685755</td>\n",
       "      <td>1.000035</td>\n",
       "      <td>0.831267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2019</td>\n",
       "      <td>309.5</td>\n",
       "      <td>58722.141</td>\n",
       "      <td>1.010919</td>\n",
       "      <td>0.461342</td>\n",
       "      <td>10.601017</td>\n",
       "      <td>1.006714</td>\n",
       "      <td>0.799732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>57100512</td>\n",
       "      <td>2020</td>\n",
       "      <td>106.9</td>\n",
       "      <td>19644.459</td>\n",
       "      <td>1.018847</td>\n",
       "      <td>0.522296</td>\n",
       "      <td>10.627618</td>\n",
       "      <td>1.008767</td>\n",
       "      <td>0.802293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3465 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     village_id  year consumption     tariff  distance_market  \\\n",
       "0      11010107  2012       123.2    16525.0         1.072830   \n",
       "1      11010107  2013      408.65    54871.5         1.072906   \n",
       "2      11010107  2014      462.25    62070.0         1.072906   \n",
       "3      11010107  2015       368.4    55941.5         1.072829   \n",
       "4      11010107  2016       368.9    67198.0         1.072828   \n",
       "...         ...   ...         ...        ...              ...   \n",
       "3460   57100512  2016       229.6    42088.5         1.021832   \n",
       "3461   57100512  2017       217.7    41186.0         1.053419   \n",
       "3462   57100512  2018      193.65    37294.5         1.024816   \n",
       "3463   57100512  2019       309.5  58722.141         1.010919   \n",
       "3464   57100512  2020       106.9  19644.459         1.018847   \n",
       "\n",
       "      distance_busstation  distance_to_nearest_road  distance_schools  \\\n",
       "0                0.518970                  0.026218          0.488517   \n",
       "1                0.518970                  0.026214          0.488534   \n",
       "2                0.518970                  0.026214          0.488534   \n",
       "3                0.518942                  0.026202          0.488617   \n",
       "4                0.518970                  0.026211          0.488551   \n",
       "...                   ...                       ...               ...   \n",
       "3460             0.461342                 10.601017          1.002348   \n",
       "3461             0.621131                 10.685755          0.961046   \n",
       "3462             0.621131                 10.685755          1.000035   \n",
       "3463             0.461342                 10.601017          1.006714   \n",
       "3464             0.522296                 10.627618          1.008767   \n",
       "\n",
       "      distance_banks  \n",
       "0           0.201774  \n",
       "1           0.201751  \n",
       "2           0.201751  \n",
       "3           0.201498  \n",
       "4           0.201729  \n",
       "...              ...  \n",
       "3460        0.799732  \n",
       "3461        0.831267  \n",
       "3462        0.831267  \n",
       "3463        0.799732  \n",
       "3464        0.802293  \n",
       "\n",
       "[3465 rows x 9 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_non_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_non_res_df = pd.merge(final_non_res_df, village_asset_wealth, how=\"left\", on = [\"village_id\", \"year\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, village_spending, how=\"left\", on = [\"village_id\", \"year\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, village_population, how=\"outer\", on = [\"village_id\", \"year\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, urbanization, how=\"outer\", on = [\"village_id\", \"year\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, building_volume, how=\"outer\", on = [\"village_id\", \"year\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, village_building_height_2018, how=\"left\", on = [\"village_id\"])\n",
    "final_non_res_df = pd.merge(final_non_res_df, landcover, how=\"outer\", on = [\"village_id\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "print(\"finish!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
